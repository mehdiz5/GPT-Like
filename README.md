# GPT-Like
The work presented in this repo is a transformer trained on the tiny shakespear text corpus, the work has been done following Andrej Karpathy's course on building a GPT-like model from scratch following the papers "Attention is all you need" and the openai GPT paper.
